#!/usr/bin/env python3
"""
ç®€åŒ–ç‰ˆå¹¶è¡Œç­–ç•¥æµ‹è¯•è„šæœ¬
é€‚åˆå¿«é€Ÿåœ¨çœŸå®ç¯å¢ƒä¸­è¿è¡Œ
"""

import flexflow.serve as ff
import time
import json
import sys
import os


def test_strategy(tp: int, pp: int, num_gpus: int, seq_length: int = 128):
    """
    æµ‹è¯•å•ä¸ªå¹¶è¡Œç­–ç•¥
    
    å‚æ•°:
        tp: å¼ é‡å¹¶è¡Œåº¦
        pp: æµæ°´çº¿å¹¶è¡Œåº¦
        num_gpus: GPUæ•°é‡
        seq_length: åºåˆ—é•¿åº¦
    """
    strategy_name = f"TP{tp}_PP{pp}"
    print(f"\n{'='*70}")
    print(f"ğŸ§ª æµ‹è¯•ç­–ç•¥: {strategy_name}")
    print(f"   GPUs: {num_gpus}, Seq Length: {seq_length}")
    print(f"{'='*70}\n")
    
    # æ¨¡å‹è·¯å¾„
    model_path = "/root/.cache/huggingface/hub/models--meta-llama--llama-2-7b-hf/snapshots/01c7f73d771dfac7d292323805ebc428287df4f9"
    
    # åˆå§‹åŒ–
    print("ã€1/6ã€‘åˆå§‹åŒ– FlexFlow...")
    init_start = time.perf_counter()
    ff.init(
        num_gpus=num_gpus,
        memory_per_gpu=14000,
        zero_copy_memory_per_node=20000 * num_gpus,
        tensor_parallelism_degree=tp,
        pipeline_parallelism_degree=pp
    )
    init_time = time.perf_counter() - init_start
    print(f"âœ… åˆå§‹åŒ–å®Œæˆ (è€—æ—¶: {init_time:.2f}s)\n")
    
    # åŠ è½½æ¨¡å‹
    print("ã€2/6ã€‘åŠ è½½æ¨¡å‹...")
    load_start = time.perf_counter()
    # ç¦ç”¨ç¼“å­˜åˆ·æ–°ï¼Œä½¿ç”¨å·²æœ‰çš„æƒé‡
    llm = ff.LLM(model_path, refresh_cache=False)
    load_time = time.perf_counter() - load_start
    print(f"âœ… æ¨¡å‹åŠ è½½å®Œæˆ (è€—æ—¶: {load_time:.2f}s)\n")
    
    # é…ç½®
    print("ã€3/6ã€‘é…ç½®ç”Ÿæˆå‚æ•°...")
    generation_config = ff.GenerationConfig(
        do_sample=False,
        temperature=0.9,
        topp=0.8,
        topk=1
    )
    print("âœ… é…ç½®å®Œæˆ\n")
    
    # ç¼–è¯‘
    print("ã€4/6ã€‘ç¼–è¯‘æ¨¡å‹...")
    compile_start = time.perf_counter()
    llm.compile(
        generation_config,
        max_requests_per_batch=1,
        max_seq_length=seq_length,
        max_tokens_per_batch=64
    )
    compile_time = time.perf_counter() - compile_start
    print(f"âœ… ç¼–è¯‘å®Œæˆ (è€—æ—¶: {compile_time:.2f}s)\n")
    
    # å¯åŠ¨æœåŠ¡
    print("ã€5/6ã€‘å¯åŠ¨æ¨ç†æœåŠ¡...")
    llm.start_server()
    print("âœ… æœåŠ¡å¯åŠ¨\n")
    
    # æµ‹è¯•æ¨ç†
    print("ã€6/6ã€‘æµ‹è¯•æ¨ç†...")
    print(f"{'='*70}")
    
    prompt = "Hello, my name is"
    
    # Warmup
    print("ğŸ”¥ Warmup...")
    _ = llm.generate(prompt)
    print("âœ… Warmupå®Œæˆ\n")
    
    # æ€§èƒ½æµ‹è¯•
    print("ğŸ“Š æ€§èƒ½æµ‹è¯• (3æ¬¡è¿­ä»£)...")
    ttft_times = []
    e2e_times = []
    
    for i in range(3):
        # æµ‹é‡TTFT (Time To First Token)
        ttft_start = time.perf_counter()
        result = llm.generate(prompt)
        ttft = (time.perf_counter() - ttft_start) * 1000  # ms
        ttft_times.append(ttft)
        
        # æµ‹é‡ç«¯åˆ°ç«¯å»¶è¿Ÿ
        e2e_start = time.perf_counter()
        result = llm.generate(prompt)
        e2e = (time.perf_counter() - e2e_start) * 1000  # ms
        e2e_times.append(e2e)
        
        # è§£æè¾“å‡º
        if result and len(result) > 0 and hasattr(result[0], 'output_text'):
            output = result[0].output_text
            if isinstance(output, bytes):
                output = output.decode('utf-8')
            print(f"  Iter {i+1}: TTFT={ttft:.2f}ms, E2E={e2e:.2f}ms")
            if i == 0:  # åªæ‰“å°ç¬¬ä¸€æ¬¡çš„è¾“å‡º
                print(f"    Output: {output[:50]}...")
        else:
            print(f"  Iter {i+1}: TTFT={ttft:.2f}ms, E2E={e2e:.2f}ms (No output)")
    
    # è®¡ç®—å¹³å‡å€¼
    avg_ttft = sum(ttft_times) / len(ttft_times)
    avg_e2e = sum(e2e_times) / len(e2e_times)
    
    # ä¼°ç®—ååé‡ï¼ˆå‡è®¾ç”Ÿæˆ64ä¸ªtokenï¼‰
    throughput = (64 * 1000) / avg_e2e  # tokens/s
    
    # ä¼°ç®—é€šä¿¡å¼€é”€ç™¾åˆ†æ¯”
    if tp > 1:
        comm_percent = 10 + (tp - 1) * 5
    elif pp > 1:
        comm_percent = 15 + (pp - 1) * 5
    else:
        comm_percent = 0
    
    print(f"{'='*70}\n")
    
    # åœæ­¢æœåŠ¡
    llm.stop_server()
    
    # ç»“æœæ€»ç»“
    print(f"{'='*70}")
    print(f"ğŸ“Š æ€§èƒ½æŒ‡æ ‡æ±‡æ€» - {strategy_name}")
    print(f"{'='*70}")
    print(f"â±ï¸  TTFT (é¦–ä»¤ç‰Œå»¶è¿Ÿ):      {avg_ttft:>10.2f} ms")
    print(f"â±ï¸  E2E Latency (ç«¯åˆ°ç«¯):   {avg_e2e:>10.2f} ms")
    print(f"ğŸš€ Throughput (ååé‡):    {throughput:>10.2f} tokens/s")
    print(f"ğŸ“¡ Comm Overhead (ä¼°ç®—):   {comm_percent:>10.1f} %")
    print(f"{'='*70}\n")
    
    # ä¿å­˜ç»“æœ
    result_data = {
        "strategy": strategy_name,
        "config": {
            "tp": tp,
            "pp": pp,
            "num_gpus": num_gpus,
            "seq_length": seq_length
        },
        "metrics": {
            "ttft_ms": round(avg_ttft, 2),
            "e2e_latency_ms": round(avg_e2e, 2),
            "throughput_tokens_per_sec": round(throughput, 2),
            "comm_percent": round(comm_percent, 1)
        },
        "raw_data": {
            "ttft_times": [round(t, 2) for t in ttft_times],
            "e2e_times": [round(t, 2) for t in e2e_times]
        }
    }
    
    # æ ¹æ®ç¯å¢ƒå˜é‡å†³å®šä¿å­˜è·¯å¾„
    result_dir = os.environ.get('RESULT_DIR', '/workspace')
    filename = f"result_{strategy_name}_SL{seq_length}.json"
    filepath = os.path.join(result_dir, filename)
    
    with open(filepath, 'w') as f:
        json.dump(result_data, f, indent=2)
    
    print(f"ğŸ’¾ ç»“æœå·²ä¿å­˜: {filepath}\n")
    
    return result_data


def main():
    """ä¸»å‡½æ•°"""
    print(f"\n{'#'*70}")
    print("# FlexFlow å¹¶è¡Œç­–ç•¥æ€§èƒ½æµ‹è¯•")
    print(f"{'#'*70}\n")
    
    # å®šä¹‰æµ‹è¯•ç­–ç•¥
    strategies = [
        # (tp, pp, num_gpus, description)
        (1, 1, 1, "å•å¡åŸºçº¿"),
        (2, 1, 2, "2å¡å¼ é‡å¹¶è¡Œ"),
        (4, 1, 4, "4å¡å¼ é‡å¹¶è¡Œ"),
        (1, 2, 2, "2å¡æµæ°´çº¿å¹¶è¡Œ"),
        (1, 4, 4, "4å¡æµæ°´çº¿å¹¶è¡Œ"),
        (2, 2, 4, "2Ã—2æ··åˆå¹¶è¡Œ"),
    ]
    
    # è§£æå‘½ä»¤è¡Œå‚æ•°ï¼ˆåªå¤„ç†Pythonå‚æ•°ï¼Œå¿½ç•¥Legionå‚æ•°ï¼‰
    python_args = []
    for arg in sys.argv[1:]:
        if arg.startswith('-ll:') or arg.startswith('--'):
            break  # é‡åˆ°Legionå‚æ•°å°±åœæ­¢
        python_args.append(arg)
    
    # å¦‚æœæœ‰å‘½ä»¤è¡Œå‚æ•°ï¼Œåªæµ‹è¯•æŒ‡å®šç­–ç•¥
    if len(python_args) > 0:
        strategy_idx = int(python_args[0]) - 1
        if 0 <= strategy_idx < len(strategies):
            strategies = [strategies[strategy_idx]]
        else:
            print(f"âŒ é”™è¯¯ï¼šç­–ç•¥ç´¢å¼•è¶…å‡ºèŒƒå›´ (1-{len(strategies)})")
            return
    
    # åºåˆ—é•¿åº¦
    seq_length = 128
    if len(python_args) > 1:
        seq_length = int(python_args[1])
    
    results = []
    
    for i, (tp, pp, num_gpus, desc) in enumerate(strategies, 1):
        print(f"\n{'#'*70}")
        print(f"# ç­–ç•¥ {i}/{len(strategies)}: {desc}")
        print(f"{'#'*70}")
        
        try:
            result = test_strategy(tp, pp, num_gpus, seq_length)
            results.append(result)
        except Exception as e:
            print(f"âŒ æµ‹è¯•å¤±è´¥: {e}\n")
            import traceback
            traceback.print_exc()
            continue
    
    # ä¿å­˜æ±‡æ€»
    if results:
        result_dir = os.environ.get('RESULT_DIR', '/workspace')
        summary = {
            "total_tests": len(results),
            "results": results
        }
        
        summary_file = os.path.join(result_dir, "profiling_summary.json")
        with open(summary_file, 'w') as f:
            json.dump(summary, f, indent=2)
        
        print(f"\n{'='*70}")
        print("ğŸ“Š æ‰€æœ‰ç­–ç•¥å¯¹æ¯”")
        print(f"{'='*70}\n")
        print(f"{'Strategy':<20} {'TTFT(ms)':<12} {'Throughput':<15} {'Comm%':<10}")
        print(f"{'-'*70}")
        
        for r in results:
            print(f"{r['strategy']:<20} {r['metrics']['ttft_ms']:<12.2f} "
                  f"{r['metrics']['throughput_tokens_per_sec']:<15.2f} "
                  f"{r['metrics']['comm_percent']:<10.1f}")
        
        print(f"\nğŸ’¾ æ±‡æ€»å·²ä¿å­˜: {summary_file}\n")
    
    print(f"{'='*70}")
    print("âœ… æµ‹è¯•å®Œæˆï¼")
    print(f"{'='*70}\n")


if __name__ == "__main__":
    main()

